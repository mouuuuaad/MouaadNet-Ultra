{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ MOUAADNET-ULTRA v2: Zero-Confidence FIX\n",
                "\n",
                "**Complete rewrite to fix the all-blue heatmap issue**\n",
                "\n",
                "### Key Fixes:\n",
                "- ‚úÖ **Decoupled Head**: Separate Heatmap/WH/Offset branches\n",
                "- ‚úÖ **Focal Loss**: Forces focus on person pixels\n",
                "- ‚úÖ **Gaussian Targets**: Soft blobs, not single pixels\n",
                "- ‚úÖ **Bias Init**: `-2.19` prevents zero output\n",
                "- ‚úÖ **1CycleLR**: 30% warmup, proper annealing\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 1Ô∏è‚É£ Setup\n",
                "!nvidia-smi\n",
                "!pip install -q torch torchvision tqdm pycocotools opencv-python onnx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 2Ô∏è‚É£ Config\n",
                "import os\n",
                "\n",
                "WORK = '/teamspace/studios/this_studio' if os.path.exists('/teamspace') else '/content'\n",
                "REPO = f'{WORK}/MouaadNet-Ultra'\n",
                "DATA = f'{WORK}/coco'\n",
                "CKPT = f'{WORK}/checkpoints_v2'\n",
                "\n",
                "os.makedirs(DATA, exist_ok=True)\n",
                "os.makedirs(CKPT, exist_ok=True)\n",
                "print(f'Work: {WORK}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 3Ô∏è‚É£ Clone/Update Repo\n",
                "if not os.path.exists(REPO):\n",
                "    !git clone https://github.com/mouuuuaad/MouaadNet-Ultra.git {REPO}\n",
                "else:\n",
                "    !cd {REPO} && git pull\n",
                "os.chdir(REPO)\n",
                "print(f'‚úÖ {os.getcwd()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 4Ô∏è‚É£ Verify COCO Dataset\n",
                "import shutil\n",
                "\n",
                "def count_images(path):\n",
                "    if not os.path.exists(path): return 0\n",
                "    return len([f for f in os.listdir(path) if f.endswith('.jpg')])\n",
                "\n",
                "EXPECTED_TRAIN = 118287\n",
                "train_count = count_images(f'{DATA}/train2017')\n",
                "val_count = count_images(f'{DATA}/val2017')\n",
                "\n",
                "print(f'Train: {train_count}/{EXPECTED_TRAIN} ({100*train_count/EXPECTED_TRAIN:.1f}%)')\n",
                "print(f'Val: {val_count}/5000')\n",
                "\n",
                "if train_count < EXPECTED_TRAIN * 0.9:\n",
                "    print('\\n‚ö†Ô∏è COCO incomplete! Re-downloading...')\n",
                "    shutil.rmtree(f'{DATA}/train2017', ignore_errors=True)\n",
                "    !wget -c http://images.cocodataset.org/zips/train2017.zip -O {DATA}/train.zip\n",
                "    !cd {DATA} && unzip -q train.zip && rm train.zip\n",
                "\n",
                "if val_count < 4500:\n",
                "    shutil.rmtree(f'{DATA}/val2017', ignore_errors=True)\n",
                "    !wget -c http://images.cocodataset.org/zips/val2017.zip -O {DATA}/val.zip\n",
                "    !cd {DATA} && unzip -q val.zip && rm val.zip\n",
                "\n",
                "if not os.path.exists(f'{DATA}/annotations/instances_train2017.json'):\n",
                "    !wget -c http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O {DATA}/ann.zip\n",
                "    !cd {DATA} && unzip -q ann.zip && rm ann.zip\n",
                "\n",
                "print('‚úÖ COCO Ready!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 5Ô∏è‚É£ Train V2 (FIXED VERSION)\n",
                "EPOCHS = 50  #@param {type:\"integer\"}\n",
                "BATCH = 32   #@param {type:\"integer\"}\n",
                "\n",
                "!python training/train_detection_v2.py \\\n",
                "    --data {DATA} \\\n",
                "    --epochs {EPOCHS} \\\n",
                "    --batch-size {BATCH} \\\n",
                "    --save-dir {CKPT} \\\n",
                "    --export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 6Ô∏è‚É£ Visualize Heatmaps (Should be RED-HOT now!)\n",
                "import torch\n",
                "import numpy as np\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "sys.path.insert(0, REPO)\n",
                "\n",
                "# Load model\n",
                "from training.train_detection_v2 import MouaadNetUltraV2, Detector\n",
                "\n",
                "model = MouaadNetUltraV2()\n",
                "ckpt = torch.load(f'{CKPT}/best.pt', map_location='cpu')\n",
                "model.load_state_dict(ckpt['model_state_dict'])\n",
                "model.eval()\n",
                "\n",
                "# Test on a sample\n",
                "img_path = f'{DATA}/val2017/000000001268.jpg'\n",
                "img = cv2.imread(img_path)\n",
                "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "# Run inference\n",
                "detector = Detector(model, device='cpu')\n",
                "tensor, scale, top, left = detector.preprocess(img_rgb)\n",
                "\n",
                "with torch.no_grad():\n",
                "    outputs = model(tensor)\n",
                "    hm = torch.sigmoid(outputs['heatmap'][0, 0]).numpy()\n",
                "\n",
                "# Plot\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
                "ax1.imshow(cv2.resize(img_rgb, (256, 256)))\n",
                "ax1.set_title('Input')\n",
                "ax1.axis('off')\n",
                "\n",
                "im = ax2.imshow(hm, cmap='hot', vmin=0, vmax=1)\n",
                "ax2.set_title(f'Heatmap (max={hm.max():.4f})')\n",
                "ax2.axis('off')\n",
                "plt.colorbar(im, ax=ax2)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{CKPT}/heatmap_test.png')\n",
                "plt.show()\n",
                "\n",
                "print(f'\\nHeatmap max: {hm.max():.4f}')\n",
                "print('Should be > 0.1 for successful training!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 7Ô∏è‚É£ Run Detection\n",
                "detections = detector.detect(img_rgb, threshold=0.3)\n",
                "\n",
                "# Draw\n",
                "vis = img_rgb.copy()\n",
                "for det in detections:\n",
                "    x1, y1, x2, y2 = [int(c) for c in det['box']]\n",
                "    cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
                "    cv2.putText(vis, f\"{det['score']:.2f}\", (x1, y1-5), \n",
                "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "plt.imshow(vis)\n",
                "plt.title(f'Detections: {len(detections)} persons')\n",
                "plt.axis('off')\n",
                "plt.savefig(f'{CKPT}/detection_test.png')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 8Ô∏è‚É£ Download Results\n",
                "print('üì¶ Files:')\n",
                "for f in os.listdir(CKPT):\n",
                "    if f.endswith(('.pt', '.onnx', '.png')):\n",
                "        print(f'   {f} ({os.path.getsize(f\"{CKPT}/{f}\")/1e6:.1f}MB)')\n",
                "\n",
                "try:\n",
                "    from google.colab import files\n",
                "    files.download(f'{CKPT}/best.pt')\n",
                "except:\n",
                "    print(f'\\nFiles at: {CKPT}')"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}